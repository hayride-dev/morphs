// Code generated by wit-bindgen-go. DO NOT EDIT.

// Package inferencestream represents the imported interface "hayride:ai/inference-stream@0.0.53".
package inferencestream

import (
	tensorstream "github.com/hayride-dev/morphs/components/ai/agents/internal/gen/hayride/ai/tensor-stream"
	"github.com/hayride-dev/morphs/components/ai/agents/internal/gen/wasi/nn/errors"
	"github.com/hayride-dev/morphs/components/ai/agents/internal/gen/wasi/nn/tensor"
	"go.bytecodealliance.org/cm"
)

// Error represents the imported type alias "hayride:ai/inference-stream@0.0.53#error".
//
// See [errors.Error] for more information.
type Error = errors.Error

// Tensor represents the imported type alias "hayride:ai/inference-stream@0.0.53#tensor".
//
// See [tensor.Tensor] for more information.
type Tensor = tensor.Tensor

// TensorStream represents the imported type alias "hayride:ai/inference-stream@0.0.53#tensor-stream".
//
// See [tensorstream.TensorStream] for more information.
type TensorStream = tensorstream.TensorStream

// NamedTensor represents the imported tuple "hayride:ai/inference-stream@0.0.53#named-tensor".
//
// Identify a tensor by name; this is necessary to associate tensors to
// graph inputs and outputs.
//
//	type named-tensor = tuple<string, tensor>
type NamedTensor cm.Tuple[string, Tensor]

// NamedTensorStream represents the imported tuple "hayride:ai/inference-stream@0.0.53#named-tensor-stream".
//
//	type named-tensor-stream = tuple<string, tensor-stream>
type NamedTensorStream cm.Tuple[string, TensorStream]

// GraphExecutionContextStream represents the imported resource "hayride:ai/inference-stream@0.0.53#graph-execution-context-stream".
//
//	resource graph-execution-context-stream
type GraphExecutionContextStream cm.Resource

// ResourceDrop represents the imported resource-drop for resource "graph-execution-context-stream".
//
// Drops a resource handle.
//
//go:nosplit
func (self GraphExecutionContextStream) ResourceDrop() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_GraphExecutionContextStreamResourceDrop((uint32)(self0))
	return
}

// Compute represents the imported method "compute".
//
// Compute the inference on the given inputs.
//
//	compute: func(inputs: list<named-tensor>) -> result<named-tensor-stream, error>
//
//go:nosplit
func (self GraphExecutionContextStream) Compute(inputs cm.List[NamedTensor]) (result cm.Result[NamedTensorStreamShape, NamedTensorStream, Error]) {
	self0 := cm.Reinterpret[uint32](self)
	inputs0, inputs1 := cm.LowerList(inputs)
	wasmimport_GraphExecutionContextStreamCompute((uint32)(self0), (*NamedTensor)(inputs0), (uint32)(inputs1), &result)
	return
}
